- [1. Switches, Logic Gates, Combinational Circuits](1.comb.md)
- [2. Sequential Circuits](2.seq.md)

---

# 3. Processors

All computational problems can be solved with a FSM. In theory. In practice even relatively
small problems might need an absurd number of states and the corresponding machine would be
impossibly expensive to build (if not absolutely impossible, for example if it needs more
components than there are atoms in the universe).

Imagine a FSM that receives six characters of 7 bits each and which is supposed to print thesse
characters in the reverse order. It will have 8_865_353_597_185 (8 trillion) states. The problem
is that the system's only memory is the register for the current state and using that to store
what characters have already been seen is not efficient. 6x7 = 42 bits to store the characters
while 8 trillion states need 44 bits to represent them.

If we use a FSM connected to a small external memory it would be much more reasonable. A memory
with 8 words of 8 bits each would be more than enough and a FSM with 12 state would be sufficient
to control it to solve the problem.

In his 1936 paper, Alan Turing imagined something even simpler than a memory: he connected his
FSM (represented in the paper as a table) to an inifinite tape with individual cells that can
hold a single symbol chosen from some alphabet. There is a read/write head that is position on
one of the tape's cells. The input to the FSM is the symbol in the current cell and the outputs
are a symbol to be written (possibly the same one of we don't wish to change the tape at this
time) and optionally a command to move the head to the cell on the left or on the right.

Today this is known as a "Turing Machine". A very interesting simulator which is available on
the web is (https://turingmachine.io/) which includes several examples.

![Turing Machine simulator](../fig/3.00.turingmachine.io.png)

Here we have the multiplication of two binary numbers. The same thing as a pure FSM would have
a much larger number of state, while here only 21 are needed. But this was created only to
study a mathematical problem of the kind "there exists a uring machine capable of..." and not
to be something practical. Each problem requires the construction of a new Turing Machine, but
towards the end of the paper there is a very interesting proposal: a Universal Turing machine
that would receive on the same tape as the input data a representation, in the form of a
sequence of symbols, of a Turing Machine that would solve the selected problem. We now call this
an "interpreter". Once such a machine was built, changing the tape would modify its behavior.
This is what we call "software".

## von Neumann and Harvard Architectures

The first computer (or "electronic brain" as the press inicially called them) was ENIAC in 1946
(previous projects were kept secret for many years). Designed by John Mauchly e J. Presper Eckert
at the University of Pennsylvania, a key limitation of the ENIAC was the need to reconfigura the
hardware using patch cable panels for each new problem. So even during its development they
started discussing its sucessor, to be called EDVAC.

One of the participants of these debates was John von Neumann and he wrote a detailed report on
these ideas. Another participant, Herman Goldstine, ended up distributing the report to several
external grupos with von Neumann as the sole author, so this style of computing is known as the
"von Neumann architecture" even though it was created by a group.

![von Neumann architecture](../fig/3.01.vonneumann.svg)

John von Neumann liked analogies with biology and so called the parts of the computers "organs"
and where the data is kept "memory" (others, specially IBM, prefered terms such as "storage" but
ended up losing this battle).

The control unit is just a FSM, which we have already seen. The arithmetic and logic unit is a
more complicated version of the adder/subtractor which we have also already seen. The input and
output are different for each computer, so for now we will ignore them.

The memory stores both data and programas (just like the tape of the Universal Turing Machine). One
bit of this memory is like a register, which we have already seen. What we didn't talk about is how
to select one bit from many, but the multiplexer is similar to the mechanism used. An interesting
feature of the von Neumann architecture is that the central processor (CPU) can be made from
a technology that is completely different from that used to make memory. Some examples:

| Computer | CPU | Memory |
|----------|-----|--------|
| EDSAC | vacuum tubes | mercury tanks |
| IAS | vacuum tubes | Williams tubes |
| LGP-30 | vacuum tubes | magnetic drum |
| PDP-8 | transistors | magnetic cores |
| modern PC | digital chips | chips with vertical capacitors |

IAS is "Institute for Advanced Studies" in Princeton where John von Neumann and his team built the
computer from his report. That is why it is more rarely referred to as the "Princeton architecture".
That is to contrast it with the "Harvard architecture", which is named after a computer that IBM
built for Howard Aiken at Harvard University. The only difference is that the data memory and program
memory are separate. The separation allows an instruction and some data to be read at the same time,
which can simplify the project. But makes it impossible for a program to modify itself.

Today all computers except for the simplest ones are hybrids: directly connected to the processor we
have two tiny memories known as the level 1 instruction cache and the level 1 data cache. These
memories only store copies of information that have been recently used by the computer. When the needed
information is not there, a level 2 unified cache is acessed. And there might b e a level 3 cache and
then finally the main memory as in von Neumann's drawing. This combines the hardware advantages of the
Harvard architecture with the programming advantages of the von Neumann architecture.

We mentioned that inputs and outputs are specific to each computer. In early computers this was reflected
in the instruction set. A computer might have one intruction to read a key and another instruction to
write to the tape. Around 1970 the idea of making input/output devices appear as special memory locations
began to become popular. This allows the processor to use "normal" instructions for everything. Of the
processors current used, only x86 (Intel and AMD) still have special instructions for input and output
and all the users use "memory mapped peripherals", which we will do as well.

## MCPU16h

In the EDAVC report the idea was put forth  of representing a program as a series numbers where the most
significant bits would represent an "order" being given to the computer (this is now called the "operation
code" or just "opcode) and the least significant bits would be the address of the memory position to be
used for this instruction. Many operations need two operands and produce a result that must be stored
somewhere. This would require 3 addresses, mas EDVAC inherited from mechanical calculators the idea
of a special register called "accumulator" which supplies one of the operands and is the destination of
the result for most of the instructions.

How many different instructions will we have? This defines how many bits we will need for the "opcode". It
turns out that it is actually possible to do everything with just a single instruction, but that is not
a good idea from an educational viewpoint. An example of such an instruction is SUBLEQ which has 3 addresses
and subtracts the value at the first address from what is at the second address (saving the result back there)
and if the result was negative or equal it jumps to the third address. Programas written for such a computer
are nearly as hard to understand as those for a Turing Machine.

A more reasonable alternative is [MCPU](https://github.com/cpldcpu/MCPU) with its 4 instructions (two bits
for the "opcode"). Tim Böscke was inspired by MPROZ and its 3 instructions, but replacing the memory to
memory operations with an accumulator in the EDVAC style greatly simplified the project.

MCPU16h has two differences: while the original MCPU is 8 bits wide so only 6 bits are left for the address
(pnly 64 bytes, which is sufficient for the simplest examples) MCPU16h, as its name implies, is 16 bits
wide and its 14 bit addresses can handle 16 thousand words of 16 bits each (32KB). And the "h" at the end
of the name is from Harvard. But like the EDVAC, MCPU16h depends on being able to modify a program while it
is running but that is not possible with a Harvard architecture. But *Digital* has a two port memory and
we will use that to make it look like there are two separate memories but what is written to one can be
read by the other.

The choice of the Harvard architecture was to allow the use of a combinational circuit for the control unit.
In a von Neumann architecture (like the original MCPU) reading an instruction happens in one cycle while
reading data in a different one. Because of this the control unit has to be a sequential circuit, which
is a bit more complex.

![PC do MCPU](../fig/3.02.mcpu_pc.svg)

With this simple circuit, at each rising clock edge the PC advances to the next word. In this case we
connected the "enable" of the PC register to 1 since we never stop changing the PC. But in a more
complete project there will be situations where that will happen (if we have to wait for the instruction
memory, for example).

So let's add the dual port memory. Port 2 is limited to reading and will be used as the instruction memory.
The control signals for port 1 are connected to constant values that won't interfere with the operation
(not writing anything, for example).

![dual port memory](../fig/3.03.mcpu_mem.svg)

When simulation starts the memory is full of 0s. Later on we will use the contents from a file to fill
in the memory, but for not we are manually editing the values of the first few words every time the
simulation starts just to see that something is actually happening. The picture shows what happens after
two clock rising edges.

The data arriving from memory (0x7777 indicating that it is the hexadecimal equivalent to the binary 0111011101110111)
is divided into a 14 bit address (0x3777) and two "opcode" bits (0 and 1). We are decoding the instructions using
only wires.

We shall implement the first of the four instructions: JCC ("Jumps if Carry Clear"). We need to choose an
"opcode" for this instruction and we selected 1 and 1.

![JCC instruction](../fig/3.04.mcpu_jcc.svg)

The multiplexer decides between jumping to the address indicated by the instruction or just adding 1 to the current PC.
The first case should only happen if the opcode is that of the JCC and if the *C* bit is 0. The 3 input AND gate
detects this situation and controls the multiplexer.

Here we are creating a single circuit, but normally the AND gate would be part of the control unit while the
multiplexer, the PC register and the adder would be part of what we call the "data path". And the memory would
be separate from the CPU.
```
clock C PC
program(0x0000, 0xC006, 0xC001, 0xC008)
0 1 0
C 1 1
C 1 2
C 0 1
C 1 2
C 0 1
C 0 6
```
To test this circuit we need to make PC an output so it can be compared during the test. We initialize the first
4 words of memory with a tiny test program. Instruction 0 will be ignored for now and instructions 1, 2 and 3
are all JCC. The first time that instruction 1 is executed (line 5 of the test) *C* é 1 and PC is incremented
to 2. In lines 7 and 9 instruction 1 is executed againm with *C* equal to 1 and *C* equal to 0 respectively.
Only in the last case it doesn't go on to 2, but instead jumps to 6.

![JCC and NOR instructions](../fig/3.05.mcpu_jcc_nor.svg)

The next instruction we will implement is NOR, for which we chose the opcode 0 and 0. We need a new 16 bit
register that we will call Acc. We will also have an output with this name to be able to use it in the tests.
The 16 bit wide NOR gets one input from Acc and the other from memory, with the result going back to Acc.

First we test JCC to check that it continues to work. Then we create a new test for NOR. The circuit must
pass both.
```
clock Acc
program(0x0004, 0x0000, 0x0001, 0x0002, 0xFFFF)
0 0
C 0
C 0xFFFB
C 4
C 0xFFFA
```
Curiously, words 0, 1 and 2 are initially used as instructions but then are used as data.

The STA instruction ("STore Accumulator") will have the opcode of 1 and 0. Acc's output will be the data
input for the memory (which was always 0 up to now). And the memory's *str* signal will be activated
by this instruction, writing to the indicated address.

![JCC, NOR and STA instructions](../fig/3.06.mcpu_jcc_nor_sta.svg)

After checking that the JCC and NOR tests continue to work, we create a new test for STA.
```
clock Acc
program(0x0004,0x8004,0xC000,0x0000,0xFFFF)
0 0
C 0
C 0
C 0
C 0xFFFF
C 0xFFFF
C 0xFFFF
C 0
C 0
C 0
C 0xFFFF
```
It isn't possible to test STA without also using other instructions. The results of writing data is
only visible when you read back that data and for that we need NOR. The test also uses JCC just to
keep the code short - a sequence of NOR, STA, NOR, STA, NOR... would be good enough test.

The last instruction, ADD, would be nearly the same as NOR if it wasn't the complication of the carry
bit. But as both ADD and NOR write to Acc we need a multiplexer to decide between them.

![the complete mcpu](../fig/3.07.mcpu.svg)

Now Acc needs to be enabled both for ADD (opcode 01) as well as NOR (opcode 00), so we can replace the
AND gate with the two inverted inputs with a simple inverter. The new adder has the same inputs as the NOR.

The *C* input is replaced by a 1 bit wide *C* register. This forces us to change the JCC test. The
definition of JCC is that *C* is cleared independently of whether the jump happens or not. This is used
so two JCC in a row will be an unconditional jump (which in other processors is a separate instruction).
The carry output of the adder is forced to 0 in the case of a JCC instruction (or a STA, but in that
case it doesn't matter).

*C* needs to be enabled for the ADD (opcode 01) and JCC (opcode 11) instructions, so the lower bit of
the opcode can be used directly for that.

With that, MCPU is complete and can execute complex programs.

### Software

We have already written small programas for the MCPU16h in the tests we have created. But indicating
each instruction directly as a hexadecimal or binary numbers, what we call "machine language", is
unfeasible for programs larger than 10 instructions or so. Fortunately, a program called "assembler"
can read a text file where each line corresponds to one instruction and some letters indicate the
operation ("NOR", "ADD", "STA" and "JCC" in the case of MCPU16h) and generate the corresponding
machine language. We can mark certain lines using textual labels and then use the same text as the
address field of other instructions so the assembler will take care of the calculation of the actual
value associated with each label.

Fancier assemblers, like *GNU as*, allow the definition  of "macros" which are texts (possibly with
some arguments) which are then exapanded everywhere they are used in a program. In this project we
use this feature to get one version of *as* (for the x86 processor, for example) to generate machine
code for the MCPU16h. These macros  are found in the file *mcpu16.inc*, which has near its start:
```
absStart:
        .macro NOR a
        .word (0x3FFF & ((\a-absStart)/2))
        .endm

        .macro ADD a
        .word (0x3FFF & ((\a-absStart)/2)) | 0x4000
        .endm

        .macro STA a
        .word (0x3FFF & ((\a-absStart)/2)) | 0x8000
        .endm

        .macro JCC a
        .word (0x3FFF & ((\a-absStart)/2)) | 0xC000
        .endm
```
A program that includes this file can have something like "JCC myLoop" and the corresponding 16 bits
will be generated. One complication is that *as* considers a label like "myLoop" to have relative
value and can't, in principle, calculate the expression which generates the instruction. The idea is
that a program might be organized as several modules and the assembler translates one at a time
and a later step links all the modules into the final program. This means that the addresses will only
be known after that. But the programs we will write for MCPU16h will be relatively simple and we will
not have more than one module. This allows us to define "absStart" as the first thing in the program
so the expresison "myLoop-absStart" can have a value that is known to the assembler.

Besides the 4 instructions that the hardware actually understands, we can use macros to define new
instructions as short sequences of these instructions. For example: CLR (clears the accumulator to zero),
LDA (loads the accumulator with a value), LDP (loads a pointer into the accumulator), LDI (loads into the
accumulator indirectly), NOT (inverts the accumulator), JMP (jumps unconditionally), JCS (jumps if *C* is
1), SUB (subtract the accumulator from a value) and CALL (calls a subroutine). The use of these
"pseudo-instructions" generates programas that are somewhat large. Programas for MCPU16h are around
10 times larger than for more reasonable processors.

The pseudo-instructions IN and OUT read and write to the last address in memory and it is up to the
circuit to detect this and read and write from a peripheral instead of memory. Two additional macros,
STARTCOUNT and COUNT, were defined to control a circuit used to measure speed so we can compare
different processors. In this project we will not implement this circuit so these pseudo-instructions
will just access the next to the last word in memory without any side effects.

The command "make ALLHEX", among other things, generates the .hex files we will use to initialize memory in our simulations.
These are saved in the *hex* directory using the .S source files in the *soft* directory. Programs *as*
and *objcopy* are used by *make*. Later on we will use *riscv32-unknown-linux-gnu-as* instead of *as*
to handle programs for RISC-V. We use .s (lower case) in the source file names in this case so *make*
can decide which assembler to use.

![MCPU16h with a terminal and a keyboard](../fig/3.08.mcputerm.svg)

The new circuit is in the lower left side. An AND with 14 inputs indicates when the last memory address
(0x3FFF) is being addressed and in this case the new multiplexer selects the data coming from the
keyboard for the NOR and ADD instructions (while STA and JCC ignore this data) instead of memory, which
is selected for any other address. Two AND gates separate the accesses to the last address for the
write (STA) and read (any other instruction) cases. Writes go to the terminal and reads come from the
keyboard.

![MCPU16h com terminal e teclado](../fig/3.08.mcputerm.svg)

The memory can be configured as "Program memory" and in "Circuit specific configurations" we can indicate
the file *hex/3.01.testTerminal.hex* as "Program file". This was generated from
```
.include "mcpu16.inc"

loop:
        LDA cp
        ADD adInst
        STA 0f
        CLR
0:      .word 0  /* will be replaced */
        STA char
        ADD minusOne
        JCC halt    /* zero terminated string */
        LDA char
        OUT
        LDA cp
        ADD one
        STA cp
        JMP loop

halt:   JMP halt

text:   .string16 "Hello world!"
cp:     .word (text-absStart)/2
char:   .word 0
```
We can step through the execution of this code by repeatedly clicking on the *clock* input. If
*Digital* opens a window and prints the expected text in it we can consider that the processor
is completely working (the NOR instruction is not seen in this listing but it is used by
pseudo-instructions such as LDA).

For a second execution of this same programa we can configure the *clock* input to pulse in
real time.

Replacing the memory initialization with *hex/3.02.sine.hex* we can see a sine wave drawn
textually on the terminal. The CORDIC algorithm avoids the use of multiplications.

A third example is the interactive game 2048. The terminal shows a 4 by 4 matrix of numbers
that have be pushed up, left, down or right by pressing keys in the small window with the
title "Keyboard". The file to initialize memory is *hex/3.03.term20248.hex*.

## drv32h

In 2010 a researh group at the University of California in Berkeley was developing a circuit
which needed to include a processor. After evaluating the available alternatives they decided
that the best option would be to create their own design. After all, this same group had
created the RISC processor in 1982 and RISC II in 1983. SOAR ("Smalltalk On A RISC") from
1984 and SPUR from 1988 had continued this tradition. So this new processor would be the
fifth in this lineage: a RISC-V.

They defined a very small set of instructions but with room for optional extensions. The
base can be 32 bits wide (RV32I or RV32E), 64 bits (RV64I or RV64E) or even 128 bits (RV128I).
The "I" and "E" variants are identical except for "I" having 32 register and "E" only 16.

An example of an extension is the "M" one which adds multiplication and division instructions.
The basic instructions are sufficient to implement these functions, but having dedicated
instructions cana accelerate some applications significantly at the cost of more expensive
hardware.  Most extensions are like this one where something that was already possible
becomes faster. An example of an extension that adds functionality is "A" which introduces
atomic operations. Without these new instructions it would not be possible for multiple
processors connected to a single memory to coordinate their activities.

With the increase in interest in the project by companies and researchers outside of Berkeley
an [independent foundation](https://riscv.org) was created to organize the standardization
and evolution of the architecture.

In drv32h (RISC-V in Digital with a RV32I base and a Harvard architecture) we will implement
only the base instructions and no extensions.

### Instructions

The basic RISC-V instructions are 32 bits long, but the bottom two bits are always 1 and 1.
The other 3 combinations are used by the "C" extension which defines 16 bit wide instructions
to make executable code more compact. The 7 bottom bits are the opcode and without the "C"
extension we have 32 possible combinations:

|         | 00...11 | 01...11 | 10...11 | 11...11 |
|---------|---------|---------|---------|---------|
| ..00011 | LOAD    | STORE   | MADD    | BRANCH  |
| ..00111 | LOAD-FP | STORE-FP| MSUB    | JALR    |
| ..01011 | cust0   | cust1   | NMSUB   | reserved|
| ..01111 | MISC-MEM| AMO     | NMADD   | JAL     |
| ..10011 | OP-IMM  | OP      | OP-FP   | SYSTEM  |
| ..10111 | AUIPC   | LUI     | reserved| reserved|
| ..11011 | OP-IMM32| OP32    | cust2   | cust3   |
| ..11111 | 48 bits | 64 bits | 48 bits | >=80 bits|

We will only implement the individual instructions JALR, JAL, AUIPC and LUI and the instruction
groups LOAD, STORE, BRANCH, OP-IMM and OP. These are only 9 of the 32 possiblities for the main
opcode. The groups of instructions use helper opcodes to select the individual instruction.

The instructions MADD, MSUB, NMSUB and NMADD and the groups LOAD-FP, STORE-FP and OP-FP are for
the floating point extensions: "F" (32 bit floating point), "D" (64 bit floating point) and
"Q" (128 bit floating point). We won't use them in this project.

The 5 bottom bits are all 1 got instructions longer than 32 bits, but none has been defined
so far. The groups OP-IMM32 and OP32 allow RV64I and RV128I to also operate on 32 bits, but
in a RV32I these instructions are not used.

Those marked as "reserved" will be used by official extensions while those marked as "custX"
are what non official extensions are supposed to use.

![PC in drv32h](../fig/3.09.drv_pc.svg)

Eliminating most of the circuito from MCPU16h we go back to having little more than the PC.
For drv32h we increase the PC from 14 to 32 bits (as well as the multiplexer and adder) and
we replace the value being added with 4. Before sending the value of PC to be used as a
memory address, we discard the bottom two bits which are used to select a byte from a 32 bit
word. The width of the memory was also increased to 32 bits but the address only went up
to 21 bits (which gives us a total of 8MB). When PC addresse byte 0x18 the memory reads word
6. As the top 9 bits are not connected, the memory will repeat 512 times over the 4GB space.

We initialize memory with *hex/3.04.sine.hex* which is the RISC-V version of the same
program that MCPU16h ran as *hex/3.02.sine.hex*. While the latter is a file with 6874 bytes,
the RISC-V version is only 373 bytes long.

The instruction is split into the two lowest bits (which should always be 1 and 1), the
5 bits of the main opcode corresponding to the above table and the remaining bits.

![JAL instruction](../fig/3.10.drv_jal.svg)

The first instruction to be implemeented is JAL ("Jump And Link") which is used for unconditional
branches and subroutine calls. There is a field with the destination register but as these
don't exist yet this field is simply not connected to anything. An immediate value of 20 bits
to be added to the PC is encoded in a somewhat complicated way. A second adder is being used
to add the immediate value to the PC and to send the result to the multiplexer that was
already there from previous projects. An idea that seems viable would be to have the multiplexer
at an input of the original adder, selecting between the constant 4 and the immediate vaue.
But this would only work due to JAL still being incomplete. The value to be saved to the
destination register is exactly PC+4 and the only way to have both that and PC+immediate is
to use two separate adders.

A 6 input AND gate combined with a 2 input one detect that the bottom 7 bits of the
instruction correspond to JAL. Their output is used to control the multiplexer.

The test corresponds to:
```
loop:   nop
        jal x31, loop
```

PC alternates between 0 and 4.

Next, we will look at the very similar groups of instructions: OP and OP-IMM.

| group | instruction | funct7  |      | funct3 | function |
|-------|-----------|---------|------|--------|--------|
| OP    | ADD       | 0000000 | rs2  | 000 | rd := rs1 + rs2 |
| OP-IMM| ADDI      | imm     | imm  | 000 | rd := rs1 + imm |
| OP    | SUB       | 0100000 | rs2  | 000 | rd := rs1 - rs2 |
| OP    | SLL       | 0000000 | rs2  | 001 | rd := rs1 << rs2 |
| OP-IMM| SLLI      | 0000000 | imm  | 001 | rd := rs1 << imm |
| OP    | SLT       | 0000000 | rs2  | 010 | rd := rs1 < rs2 |
| OP-IMM| SLTI      | imm     | imm  | 010 | rd := rs1 < imm |
| OP    | SLTU      | 0000000 | rs2  | 011 | rd := rs1 < rs2 (unsigned) |
| OP-IMM| SLTIU     | imm     | imm  | 011 | rd := rs1 < imm (unsigned) |
| OP    | XOR       | 0000000 | rs2  | 100 | rd := rs1 XOR rs2 |
| OP-IMM| XORI      | imm     | imm  | 100 | rd := rs1 XOR imm |
| OP    | SRL       | 0000000 | rs2  | 101 | rd := rs1 >> rs2 (unsigned) |
| OP-IMM| SRLI      | 0000000 | imm  | 101 | rd := rs1 >> imm (unssigned) |
| OP    | SRA       | 0100000 | rs2  | 101 | rd := rs1 >> rs2 |
| OP-IMM| SRAI      | 0100000 | imm  | 101 | rd := rs1 >> imm |
| OP    | OR        | 0000000 | rs2  | 110 | rd := rs1 OR rs2 |
| OP-IMM| ORI       | imm     | imm  | 110 | rd := rs1 OR imm |
| OP    | AND       | 0000000 | rs2  | 111 | rd := rs1 AND rs2 |
| OP-IMM| ANDI      | imm     | imm  | 111 | rd := rs1 AND imm |

The only difference between the two groups is the lack of a SUBI, but since the
immediate value is signed this instruction is unnecessary.

Two new 6 input AND gates indicate the OP and OP-IMM groups. The *PC* output
was replaced by a *PC* probe. It takes up less space yet the tests can use
it just the same. We also added probes for *JAL*, *OP* and *OP-IMM* so we
can test these signals.

![probes](../fig/3.11.drv_jal_op_opimm.svg)

![registers](../fig/3.12.drv_jal_op_opimm_reg.svg)

---

- [4. FPGAs and Shin JAMMA](4.fpga.md)
- [5. Video and Audio](5.av.md)
- [6. Pegasus 42](6.pegasus42.md)
- [A. History](A.hist.md)
